{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Plots, Random, Statistics;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gen_real_samples(n=100)\n",
    "    # Generate random inputs between -0.5 and 0.5\n",
    "    X1 = rand(n) .- 0.5\n",
    "\n",
    "    # compute their outputs\n",
    "    X2 = X1.^2 \n",
    "    X1 = reshape(X1, (n,1))\n",
    "    X2 = reshape(X2, (n,1))\n",
    "    X = [X1 X2]\n",
    "\n",
    "    # include labels\n",
    "    y = ones((n,1))\n",
    "\n",
    "    return X, y\n",
    "end\n",
    "\n",
    "function generate_latent_points(latent_dim, n)\n",
    "    x_input = rand(latent_dim*n)\n",
    "    x_input = reshape(x_input, n, latent_dim)\n",
    "    return x_input\n",
    "end\n",
    "\n",
    "function gen_fake_samples(generator, latent_dim, n=100)\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "\n",
    "    X = generator(x_input).data\n",
    "    \n",
    "    y = zeros((n,1))\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "n_inputs = 2;\n",
    "n_outputs = 2;\n",
    "latent_dim = 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Chain(\n",
    "    x-> reshape(x, latent_dim, :),\n",
    "    Dense(latent_dim, 15, relu),\n",
    "    Dense(15, n_outputs, leakyrelu)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Chain(\n",
    "    x-> reshape(x, n_inputs, :),\n",
    "    Dense(n_inputs, 25, relu),\n",
    "    Dense(25, 1, sigmoid)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: ADAM(params) is deprecated; use ADAM(η::Float64) instead\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n"
     ]
    }
   ],
   "source": [
    "opt_gen  = ADAM(params(gen), 0.001f0, β1 = 0.5);\n",
    "opt_disc = ADAM(params(disc), 0.001f0, β1 = 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zero_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nullify_grad!(p)\n",
    "  if typeof(p) <: TrackedArray\n",
    "    p.grad .= 0.0f0\n",
    "  end\n",
    "  return p\n",
    "end\n",
    "\n",
    "function zero_grad!(model)\n",
    "  model = mapleaves(nullify_grad!, model)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Training\n",
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bce (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary cross entropy\n",
    "function bce(ŷ, y)\n",
    "    neg_abs = -abs.(ŷ)\n",
    "    mean(relu.(ŷ) .- ŷ .* y .+ log.(1 .+ exp.(neg_abs)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: e not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: e not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[12]:45"
     ]
    }
   ],
   "source": [
    "training_steps = 0\n",
    "verbose_freq = 100\n",
    "\n",
    "function train(x)\n",
    "    global training_steps\n",
    "  \n",
    "    # z = rand(dist, noise_dim, BATCH_SIZE) |> gpu\n",
    "    realX, realy = gen_real_samples(x)\n",
    "   \n",
    "    zero_grad!(disc)\n",
    "   \n",
    "    D_real = disc(realX)\n",
    "    D_real_loss = bce(D_real, realy)\n",
    "  \n",
    "    fakeX, fakey = gen_fake_samples(gen, latent_dim, x)\n",
    "\n",
    "    D_fake = disc(fakeX)\n",
    "    D_fake_loss = bce(D_fake, fakey)\n",
    "  \n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "  \n",
    "    Flux.back!(D_loss)\n",
    "    opt_disc()\n",
    "  \n",
    "    zero_grad!(gen)\n",
    "    \n",
    "    # z = rand(dist, noise_dim, BATCH_SIZE) |> gpu\n",
    "    fakeX, fakey = gen_fake_samples(gen, latent_dim, x)\n",
    "    D_fake = disc(fakeX)\n",
    "    G_loss = bce(D_fake, ones(x))\n",
    "  \n",
    "    Flux.back!(G_loss)\n",
    "    opt_gen()\n",
    "  \n",
    "    if training_steps % verbose_freq == 0\n",
    "        println(\"D Loss: $(D_loss.data) | G loss: $(G_loss.data)\")\n",
    "    end\n",
    "    \n",
    "    training_steps += 1\n",
    "    param(0.0f0)\n",
    "end\n",
    "\n",
    "# set to 10,000 if you have a few minutes to wait and see better results\n",
    "NUM_EPOCHS = 1000;\n",
    "\n",
    "\"\"\"\n",
    "for e = 1:NUM_EPOCHS\n",
    "    println(\"Epoch $e: \")\n",
    "    train(500)\n",
    "end\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disc = [[i, i^2] for i ∈ -0.5:0.01:0.5]\n",
    "println(\"Average discrimenator correct guess: \", mean(disc.(test_disc)))\n",
    "\n",
    "x_fake, y_fake = gen_fake_samples(gen, latent_dim)\n",
    "scatter(x_fake[1, :], x_fake[2, :], title=\"GAN Attempt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
